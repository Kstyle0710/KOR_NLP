{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regexpression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역슬래시(\\)를 사용한 주요 문자규칙\n",
    " - \\\\   역슬래시 자체를 의미\n",
    " - \\d   모든 숫자를 의미 [0-9]와 동일\n",
    " - \\D   숫자를 제외한 모든 문자 [^0-9]와 동일\n",
    " - \\s   공백을 의미 [\\t\\n\\r\\f\\v]와 동일\n",
    " - \\S   공백을 제외한 모든 문자를 의미 [^\\t\\n\\r\\f\\v]와 동일\n",
    " - \\w   문자와 숫자를 의미 [a-zA-Z0-9]와 동일  (특수문자 제외)\n",
    " - \\W   문자와 숫자를 제외한 다른 문자를 의미 [^a-zA-Z0-9]와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='ab'>\n",
      "None\n",
      "<re.Match object; span=(0, 2), match='ab'>\n"
     ]
    }
   ],
   "source": [
    "chk = 'ab*'     \n",
    "# .은 반드시 한개의 문자, ?는 1개 or 0개, *은 0개 이상, +는 1개 이상\n",
    "print(re.match(chk, 'abc'))\n",
    "print(re.match(chk, 'c'))\n",
    "print(re.match(chk, 'ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 1), match='d'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "chk = '[^abc]'     \n",
    "# []안에 한개의 문자와 매치,  앞에 ^ 붙으면 반대\n",
    "print(re.match(chk, 'abc'))\n",
    "print(re.match(chk, 'd'))\n",
    "print(re.match(chk, 'cd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='a'>\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "chk = 'a|b'     \n",
    "#  | 또는의 의미\n",
    "print(re.match(chk, 'ac'))\n",
    "print(re.match(chk, 'd'))\n",
    "print(re.match(chk, 'cd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99 ms ± 294 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "check = 'ab'\n",
    "for i in range(1000):\n",
    "    re.match(check, 'abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785 µs ± 34 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r = re.compile('ab')\n",
    "for i in range(1000):\n",
    "    r.match('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='a'>\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(0, 2), match='ab'>\n"
     ]
    }
   ],
   "source": [
    "## search는 match와 다르게 문자열의 전체를 검사\n",
    "chk = 'ab.'\n",
    "\n",
    "print(re.search('a', chk))\n",
    "print(re.match('kkab', chk))\n",
    "print(re.search('kkab', chk))\n",
    "print(re.match('ab', chk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가\n",
      "abCdek\n",
      "가\n",
      "가\n"
     ]
    }
   ],
   "source": [
    "print(re.sub('[a-z]', 'abcdek', \"가\"))\n",
    "print(re.sub('[^a-z]', 'abCdek', \"가\"))\n",
    "print(re.sub('[a-z]', 'abcdEk', \"가\"))\n",
    "print(re.sub('[a-z]', 'ABCD', \"가\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '5']\n",
      "['!', ',', ' ', '*', '&', ',', ' ', '#', '$']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall('[\\d]', '1ab c2d, 3fg, gh5'))\n",
    "print(re.findall('[\\W]', '!DHFK, adf*&dfd, df#$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<callable_iterator object at 0x000001A1290648C8>\n",
      "<callable_iterator object at 0x000001A1290647C8>\n"
     ]
    }
   ],
   "source": [
    "iter1 = re.finditer('[\\d]', '1ab c2d, 3fg, gh5')\n",
    "print(iter1)\n",
    "iter2 = re.finditer('[\\W]', '!DHFK, adf*&dfd, df#$')\n",
    "print(iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<re.Match object; span=(0, 1), match='1'>, <re.Match object; span=(5, 6), match='2'>, <re.Match object; span=(9, 10), match='3'>, <re.Match object; span=(16, 17), match='5'>]\n",
      "[<re.Match object; span=(0, 1), match='!'>, <re.Match object; span=(5, 6), match=','>, <re.Match object; span=(6, 7), match=' '>, <re.Match object; span=(10, 11), match='*'>, <re.Match object; span=(11, 12), match='&'>, <re.Match object; span=(15, 16), match=','>, <re.Match object; span=(16, 17), match=' '>, <re.Match object; span=(19, 20), match='#'>, <re.Match object; span=(20, 21), match='$'>]\n"
     ]
    }
   ],
   "source": [
    "print([x for x in iter1])\n",
    "print([x for x in iter2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural', 'language', '분석은', '어려운', '일이다', '.', '그러나', 'keep', 'going']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"natural language 분석은 어려운 일이다. 그러나 keep going\"\n",
    "tokens = word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language 분석은 어려운 일이다.',\n",
       " '그러나 keep going \\n3 단계 방역 지침을 시행하고 있습니다.',\n",
       " 'covid19 situation is getting worsen.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = \"natural language 분석은 어려운 일이다. \\n 그러나 keep going \\n3 단계 방역 지침을 시행하고 있습니다. \\n covid19 situation is getting worsen.\"\n",
    "\n",
    "tokens = sent_tokenize(sentences)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'text_to_sequence' from 'keras.preprocessing.text' (c:\\my_develop\\nlp_prac\\venv\\lib\\site-packages\\keras\\preprocessing\\text.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-c321317ae72d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext_to_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Where ther\\'s a will, there\\'s a way'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext_to_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'text_to_sequence' from 'keras.preprocessing.text' (c:\\my_develop\\nlp_prac\\venv\\lib\\site-packages\\keras\\preprocessing\\text.py)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_sequence\n",
    "sentence = 'Where there\\'s a will, there\\'s a way'\n",
    "text_to_sequence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
